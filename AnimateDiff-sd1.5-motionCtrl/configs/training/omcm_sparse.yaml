image_finetune: false

output_dir: "./experiments"
pretrained_model_path: "models/StableDiffusion/stable-diffusion-v1-5"

unet_additional_kwargs:
  use_inflated_groupnorm:     true # v2: without this line
  use_motion_module:          true
  motion_module_resolutions:  [1,2,4,8]
  motion_module_mid_block:    false # v2: true
  motion_module_type:         Vanilla

  motion_module_kwargs:
    num_attention_heads:                 8
    num_transformer_block:               1
    attention_block_types:               [ "Temporal_Self", "Temporal_Self" ]
    temporal_position_encoding:          true
    temporal_position_encoding_max_len:  32
    temporal_attention_dim_div:          1
    zero_initialize:                     true


noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

train_data:
  target: motionctrl.data.webvid_motion_trajectory_anyspatio.WebVid
  params:
    data_dir: datasets/WebVid
    meta_path: datasets/WebVid/meta_data/results_2M_train.csv
    motion_seg_list: datasets/WebVid/motion_seg_list_v2.txt
    video_length: 16
    frame_stride:
    - 1
    - 2
    trajectory_type: sparse
    spatial_transform: align2_256
    resolution: [512,512]
    load_raw_resolution: True
  sample_size: 512
  sample_n_frames: 16

validation_data:
  prompts:
    - "a sunflower swaying in the wind."
    - "a man surfing."

  traj_paths:
    - ./examples/motionctrl_animatediff_512/swaying_0/swaying_0.npy
    - ./examples/motionctrl_animatediff_512/curve_0/curve_0.npy

  num_inference_steps: 50
  guidance_scale: 8.

trainable_modules: ~

unet_checkpoint_path: "models/Motion_Module/v3_sd15_mm.ckpt"


learning_rate:    5.e-5
train_batch_size: 1
gradient_accumulation_steps: 8

max_train_epoch:      -1
max_train_steps:      1000000
checkpointing_epochs: -1
checkpointing_steps:  1000
save_checkpoint_steps: 5000

validation_steps:       1000
validation_steps_tuple: [2, 50, 500]

global_seed: 42
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: false

enable_cmcm: False
appearance_debias: 5

# omcm
enable_omcm: true
omcm_min_step: 700
min_step_prob: 0.8

omcm_config: 
  pretrained: ~ # The path to the dense model
  params:
    channels:
      - 320
      - 640
      - 1280
      - 1280
    nums_rb: 2
    cin: 128 # 2 * 8 * 8
    sk: True
    use_conv: False

use_optical_flow: false